{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Classification of Handwritten digits\n> This code provides a simple example of a classification of images with handwritten digits (going from 0 to 9), using the KNN method from the scikit-learn library.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn import datasets\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "You will save all the relevant information in the variable <b>digits</b>. With the attribute <b>.target</b> you can access the labels (in this case the labels are numbers from 0 to 9 depending on what is written in the image). The attribute <b>.images</b> allows you to access to the images in their matrix form (8x8 pixels), while <b>.data</b> contains the flatten version, namely, the pixels in vector form (As you want to work with features, these are the ones that you need!).\n\nIt can be convenient to look at the images (if you are using jupyter try, probably you are not going to be able to display the images, do not worry for that, just skip it).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Set global random state\nnp.random.seed(31415)\n\n# Load the dataset\ndigits = datasets.load_digits()\n\n# Print the relevant information\nprint(\"Labels' size: \", digits.target.shape) # One label (0, 1, 2, 3, 4, 5, 6, 7, 8 or 9) per subject\nprint(\"Features' size: \", digits.data.shape) # [no. of subject, no. of features]\nprint(\"Images' size: \", digits.images.shape) # [no. of subject, width, height]\n\n# Display samples of images\nfig = plt.figure(figsize=(20,10))\n\nfor i in range(10):\n    a = fig.add_subplot(1, 10, i+1)\n    imgplot = plt.imshow(digits.images[i])\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": "Labels' size:  (1797,)\nFeatures' size:  (1797, 64)\nImages' size:  (1797, 8, 8)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Before starting with the machine learning, you want to correctly split your data. You need to obtain a training set of 80% of your original data and the rest for a testing set. You're goint to use <b>X</b> to save your features and <b>Y</b> for the labels.\n\nAs you already saw in the previous images plots, your dataset comes in order (zero first, then a one, etc), therefore you need to shuffle your data before using it to train the ML method so that this does not influence the result. The shuffling should be among subjects, but you need to keep the features corresponding to a specific subject matching the label of the subject, therefore the shuffling shoud be made only by row (remember from your previous prints that the subjects are stored by row)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Identify the number of samples and determine a treshold to split\nlength_data = len(digits.data)\nsplit_data = round(length_data*0.8)\n\n# Split in training and testing sets\nX_train = digits.data[:split_data, :]\nX_test = digits.data[split_data:, :]\nY_train = digits.target[:split_data]\nY_test = digits.target[split_data:]\n\nprint(\"\\033[1m\" + \"Data size\" + \"\\033[0m\")\nprint(\"x train: \", X_train.shape)\nprint(\"y train: \", Y_train.shape)\nprint(\"x test: \", X_test.shape)\nprint(\"y test: \", Y_test.shape)\nprint(\"\\n\")\n\n# Concatenate features and labels to shuffle accordingly\ntrain = np.c_[X_train, Y_train]\ntest = np.c_[X_test, Y_test]\n\nprint(\"\\033[1m\" + \"Feature + label size\" + \"\\033[0m\")\nprint(\"train: \", train.shape)\nprint(\"test: \", test.shape)\nprint(\"\\n\")\n\nprint(\"\\033[1m\" + \"Examples before shuffling\" + \"\\033[0m\")\nprint(\"train:\\n\", train[:5,55:])\nprint(\"test:\\n\", test[:5,55:])\nprint(\"\\n\")\n\n# Shuffle the data\nnp.random.shuffle(train)\nnp.random.shuffle(test)\n\nprint(\"\\033[1m\" + \"Examples after shuffling\" + \"\\033[0m\")\nprint(\"shuffled train:\\n\", train[:5,55:])\nprint(\"shuffled test:\\n\", test[:5,55:])\n\n# Separate features and labels\nX_train = train[:,:-1]\nY_train = train[:,-1]\nX_test = test[:,:-1]\nY_test = test[:,-1]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1mData size\u001b[0m\nx train:  (1438, 64)\ny train:  (1438,)\nx test:  (359, 64)\ny test:  (359,)\n\n\n\u001b[1mFeature + label size\u001b[0m\ntrain:  (1438, 65)\ntest:  (359, 65)\n\n\n\u001b[1mExamples before shuffling\u001b[0m\ntrain:\n [[ 0.  0.  0.  6. 13. 10.  0.  0.  0.  0.]\n [ 0.  0.  0.  0. 11. 16. 10.  0.  0.  1.]\n [ 0.  0.  0.  0.  3. 11. 16.  9.  0.  2.]\n [ 0.  0.  0.  7. 13. 13.  9.  0.  0.  3.]\n [ 0.  0.  0.  0.  2. 16.  4.  0.  0.  4.]]\ntest:\n [[ 0.  0.  2. 12. 16. 13.  6.  0.  0.  3.]\n [ 0.  0.  0.  0. 12.  9.  0.  0.  0.  4.]\n [ 0.  0.  0.  5. 16. 16. 14.  1.  0.  5.]\n [ 0.  0.  0.  5. 13. 16. 12.  1.  0.  6.]\n [ 0.  0.  0.  3. 16.  2.  0.  0.  0.  7.]]\n\n\n\u001b[1mExamples after shuffling\u001b[0m\nshuffled train:\n [[ 0.  0.  0. 10. 15. 12.  3.  0.  0.  3.]\n [ 0.  0.  0.  3. 15. 16. 10.  1.  0.  6.]\n [ 0.  0.  0.  0. 10. 16. 12.  0.  0.  8.]\n [ 0.  0.  0.  0.  3. 15. 13.  0.  0.  1.]\n [ 0.  0.  0. 10. 16. 13.  3.  0.  0.  2.]]\nshuffled test:\n [[ 0.  0.  0.  7. 16. 16. 15.  0.  0.  0.]\n [ 0.  0.  0.  4. 15. 15. 12.  3.  0.  6.]\n [ 0.  0.  2. 13. 12.  9.  0.  0.  0.  2.]\n [ 0.  0.  3. 16. 15.  8.  7.  4.  0.  2.]\n [ 0.  0.  0. 11. 15.  8.  1.  0.  0.  5.]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Now you are ready to start the training and testing. Remember that the training is made with the features (<b>X</b>) and labels (<b>Y</b>) corresponding to the training set, while the testing only requires the features (<b>X</b>) corresponding to the testing set, you do not provide the labels (<b>Y</b>) in this case as you don't want to give the correct answer to the method, it should guess!!.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define the ML method to use\n\nmethod =KNeighborsClassifier(n_neighbors=3)\n\nmethod.fit(X_train, Y_train) # Train the method\npred = method.predict(X_test) # Generate the predictions\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Until now you have your method trained and you made predictions using data that the method did not see before (the testing set). Now is time to test how good were your predictions. You stored your predictions in the variable <b>pred</b>, now let's compare with the actual results (<b>Y_test</b>) using some metrics.\n\nThe confusion matrix you will display corresponds only to the label <b>0</b>. Plot by yourself the confusion matrices corresponding to the rest of the labels (this does not apply if you are using jupyter try, as it is not available, if this is the case replace the <b>ConfusionMatrixDisplay</b> command with a simple <b>print(cm)</b>, it is not visually pleasing but serves the purpose).\n\n<b>Hint:</b> The variable <b>cm</b> saves all the confusion matrices you need, you can access to each of them by indexing (<b>cm[index]</b>)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "ename": "<class 'SyntaxError'>",
          "evalue": "unterminated string literal (detected at line 1) (<ipython-input-16-d022f4557717>, line 1)",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [16]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Until now you have your method trained and you made predictions using data that the method did not see before (the testing set). Now is time to test how good were your predictions. You stored your predictions in the variable <b>pred</b>, now let's compare with the actual results (<b>Y_test</b>) using some metrics.\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "acc = accuracy_score(Y_test, pred) # accuracy\ncm = multilabel_confusion_matrix(Y_test, # confusion matrix per label\n                            pred,\n                            labels=[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n\n\nprint(\"The accuracy is: \", round(acc*100, 2), \"%\")\nprint(cm)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "text": "The accuracy is:  96.66 %\n[[[324   0]\n  [  0  35]]\n\n [[321   2]\n  [  0  36]]\n\n [[325   0]\n  [  0  34]]\n\n [[321   1]\n  [  4  33]]\n\n [[322   0]\n  [  3  34]]\n\n [[319   3]\n  [  0  37]]\n\n [[322   0]\n  [  0  37]]\n\n [[321   2]\n  [  0  36]]\n\n [[323   3]\n  [  2  31]]\n\n [[321   1]\n  [  3  34]]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "You have a complete program that trains a ML method, makes predictions and evaluates them. Now you should try with different ML methods. The following methods are the ones expected:\n\n<b>Naive Bayes</b>:\n\nYou can import it using <i>from sklearn.naive_bayes import GaussianNB</i> in the first cell\n\nYou define the method using <i>GaussianNB()</i>\n    \n\n<b>CART</b>:\n\nImport with <i>from sklearn.tree import DecisionTreeClassifier</i>\n\nDefine with <i>DecisionTreeClassifier(random_state=0)</i>\n\nIn this case, after fitting the method (the training part) use <i>tree.plot_tree(method)</i> to visualize the tree.\n    \n\n<b>LDA</b>:\n\nImport with <i>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis</i>\n\nDefine with <i>LinearDiscriminantAnalysis()</i>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "When you finish use an extra markdown cell at the end to explain which method you think that provided the best result.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    }
  ]
}